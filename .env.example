# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=true

# Database Configuration
DATABASE_URL=postgresql://dev:dev@localhost:5433/ai_agents

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# Connection Pool Settings
DB_POOL_MIN=2
DB_POOL_MAX=10

# LLM Provider Configuration
# Options: ollama, groq
LLM_PROVIDER=ollama

# Ollama Settings (for local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Groq Settings (for cloud LLM - requires free API key from console.groq.com)
GROQ_API_KEY=
GROQ_MODEL=llama3-8b-8192

# Available Ollama Models:
# - llama3.2 (recommended - 3B params, fast)
# - llama3.2:1b (tiny, very fast)
# - mistral (7B params, good quality)
# - phi3 (3.8B params, efficient)
# - gemma2 (9B params, high quality)
#
# Pull models with: ollama pull llama3.2

# Available Groq Models (all free tier):
# - llama3-8b-8192 (recommended - fast, good)
# - llama3-70b-8192 (high quality, slower)
# - mixtral-8x7b-32768 (very good, long context)
# - gemma2-9b-it (good quality)

# Sentiment Analysis Configuration
# Options: vader (fast, rule-based) or finbert (accurate, ML-based)
SENTIMENT_ANALYZER=vader

# FinBERT Model (if using finbert)
# Options: ProsusAI/finbert, yiyanghkust/finbert-tone
FINBERT_MODEL=ProsusAI/finbert