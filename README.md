# AI Agent Builder

> Multi-agent stock analysis system with LLM and RAG capabilities

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue.svg)](https://www.postgresql.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**A flexible, production-ready framework for building AI-powered stock analysis agents with support for multiple LLM providers and RAG configurations.**

---

## ğŸ¯ Features

### **Multi-Agent System**
- âœ… Flexible agent framework with decorator-based creation
- âœ… Agent registry for dynamic management
- âœ… Consensus calculation from multiple signals
- âœ… Built-in caching and performance optimization

### **LLM Integration**
- âœ… **Ollama** - Local inference (recommended for testing)
- âœ… **OpenAI** - GPT models (production-ready)
- âœ… **Anthropic** - Claude models (high quality)
- âœ… Unified interface across all providers

### **RAG (Retrieval-Augmented Generation)**
- âœ… **3 Embedding Options**: Simple hash, Sentence Transformers, Ollama
- âœ… **3 Vector Stores**: In-memory, ChromaDB, FAISS
- âœ… Semantic search through SEC filings
- âœ… Context-aware analysis with database integration

### **Infrastructure**
- âœ… PostgreSQL with connection pooling (50x faster)
- âœ… Docker containerization
- âœ… FastAPI with automatic OpenAPI docs
- âœ… Comprehensive mock database for testing
- âœ… Input validation and SQL injection prevention

---

## ğŸš€ Quick Start

See [QUICK_START.md](docs/QUICK_START.md) for detailed instructions.

```bash
# 1. Clone and setup
git clone <your-repo>
cd ai-agent-builder

# 2. Install core dependencies
pip install -r requirements.txt

# 3. Start PostgreSQL (Docker)
make start

# 4. Load mock data
make seed

# 5. Run API
python main.py
```

Visit: **http://localhost:8000/docs**

---

## ğŸ“ Project Structure

```
ai-agent-builder/
â”œâ”€â”€ agent_builder/           # Main package
â”‚   â”œâ”€â”€ core/               # Config, database, security
â”‚   â”‚   â”œâ”€â”€ config.py       # Configuration management
â”‚   â”‚   â”œâ”€â”€ database.py     # Connection pooling
â”‚   â”‚   â””â”€â”€ security.py     # Input validation
â”‚   â”œâ”€â”€ agents/             # Agent system
â”‚   â”‚   â”œâ”€â”€ base.py         # Base classes
â”‚   â”‚   â”œâ”€â”€ context.py      # Data access
â”‚   â”‚   â””â”€â”€ registry.py     # Agent management
â”‚   â”œâ”€â”€ llm/                # LLM providers
â”‚   â”‚   â”œâ”€â”€ base.py         # Base interface
â”‚   â”‚   â”œâ”€â”€ providers.py    # Ollama, OpenAI, Anthropic
â”‚   â”‚   â””â”€â”€ prompts.py      # Prompt templates
â”‚   â”œâ”€â”€ rag/                # RAG system
â”‚   â”‚   â”œâ”€â”€ embeddings.py   # Embedding models
â”‚   â”‚   â”œâ”€â”€ vectorstores.py # Vector databases
â”‚   â”‚   â”œâ”€â”€ retriever.py    # Data retrieval
â”‚   â”‚   â””â”€â”€ rag_engine.py   # RAG orchestration
â”‚   â””â”€â”€ api/                # FastAPI application
â”‚       â”œâ”€â”€ app.py          # Application setup
â”‚       â””â”€â”€ routes.py       # API endpoints
â”œâ”€â”€ examples/               # Example agents
â”‚   â”œâ”€â”€ register_agents.py  # Simple test agents
â”‚   â”œâ”€â”€ llm_agent_example.py # LLM-powered agents
â”‚   â””â”€â”€ rag_agents.py       # RAG-powered agents
â”œâ”€â”€ database/               # Database setup
â”‚   â”œâ”€â”€ mock_data.sql       # Mock data schema
â”‚   â””â”€â”€ setup_mock_db.py    # Database initialization
â”œâ”€â”€ docker-compose.yml      # Docker configuration
â”œâ”€â”€ Makefile               # Convenient commands
â””â”€â”€ main.py                # Entry point
```

---

## ğŸ¤– Creating Agents

### **Simple Agent**
```python
from agent_builder import agent

@agent("PE Ratio Analyzer", "Analyzes P/E ratios")
def pe_agent(ticker, context):
    pe = context.get_fundamental("pe_ratio")
    
    if pe < 15:
        return "bullish", 0.8, "Low P/E indicates value"
    elif pe > 30:
        return "bearish", 0.7, "High P/E suggests overvaluation"
    
    return "neutral", 0.5, f"Average P/E: {pe}"

# Register
from agent_builder import get_registry
registry = get_registry()
registry.register(pe_agent.agent, weight=1.2, tags=["fundamental"])
```

### **LLM-Powered Agent**
```python
from agent_builder.llm import get_llm_provider, PromptTemplates

@agent("LLM Analyzer", "Uses AI for analysis")
def llm_agent(ticker, context):
    llm = get_llm_provider("ollama")
    
    fundamentals = context.get_fundamentals()
    prompt = PromptTemplates.fundamental_analysis(ticker, fundamentals)
    
    response = llm.generate(prompt, temperature=0.3)
    parsed = PromptTemplates.parse_llm_response(response.content)
    
    return parsed["signal"], parsed["confidence"], parsed["reasoning"]
```

### **RAG-Powered Agent**
```python
from agent_builder.rag import RAGEngine

@agent("RAG Analyzer", "Uses RAG for context-aware analysis")
def rag_agent(ticker, context):
    # Create RAG engine
    rag = RAGEngine(
        db=context.db,
        embedding="sentence-transformers",
        vectorstore="chroma"
    )
    
    # Index and search SEC filings
    rag.index_sec_filings(ticker)
    rag_context = rag.get_relevant_context(ticker, "growth strategy")
    
    # Use context in LLM
    llm = get_llm_provider("ollama")
    response = llm.generate(f"{rag_context}\n\nAnalyze {ticker}.")
    
    # Parse and return
    parsed = PromptTemplates.parse_llm_response(response.content)
    return parsed["signal"], parsed["confidence"], parsed["reasoning"]
```

---

## ğŸŒ API Usage

### **Run Analysis**
```bash
POST /analyze
{
  "ticker": "AAPL",
  "agent_ids": ["pe_ratio_agent", "llm_analyzer"]  # optional
}

Response:
{
  "analysis_id": "abc-123",
  "status": "pending"
}
```

### **Get Results**
```bash
GET /analyze/{analysis_id}

Response:
{
  "ticker": "AAPL",
  "status": "completed",
  "signals": [
    {
      "agent_name": "PE Ratio Analyzer",
      "signal_type": "bullish",
      "confidence": 0.8,
      "reasoning": "Low P/E indicates value"
    }
  ],
  "consensus": {
    "signal": "bullish",
    "confidence": 0.75,
    "agreement": 0.88
  }
}
```

### **Manage Agents**
```bash
GET /agents                    # List all agents
POST /agents/{id}/enable       # Enable agent
POST /agents/{id}/disable      # Disable agent
```

---

## ğŸ³ Docker Commands

```bash
make start      # Start PostgreSQL
make stop       # Stop database
make shell      # Open database shell
make logs       # View logs
make seed       # Load mock data
make test       # Test connection
make backup     # Backup database
make clean      # Remove containers
```

---

## ğŸ“ Configuration

### **Environment Variables** (`.env`)
```bash
# Database
DATABASE_URL=postgresql://agent_user:agent_password@localhost:5432/agentbuilder

# API
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=true

# LLM Provider (choose one)
LLM_PROVIDER=ollama              # or "openai" or "anthropic"
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# OpenAI (if using)
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4

# Anthropic (if using)
# ANTHROPIC_API_KEY=sk-ant-...
# ANTHROPIC_MODEL=claude-3-sonnet-20240229
```

### **RAG Configuration**
```python
# In your agent code - choose embedding and vector store
rag = RAGEngine(
    db=context.db,
    embedding="sentence-transformers",  # or "simple" or "ollama"
    vectorstore="chroma"                # or "memory" or "faiss"
)
```

---

## ğŸ“Š Mock Database

Includes test data for **5 stocks**: AAPL, TSLA, MSFT, GOOGL, NVDA

**Tables:**
- `mock_fundamentals` - Financial metrics (P/E, ROE, margins, etc.)
- `mock_prices` - Historical OHLCV + technical indicators
- `mock_news` - News articles with sentiment scores
- `mock_analyst_ratings` - Buy/sell ratings from major firms
- `mock_insider_trades` - Insider buying/selling activity
- `mock_sec_filings` - 10-K/10-Q filings with full text
- `mock_options` - Options data for volatility analysis
- `mock_macro_indicators` - Economic indicators (Fed rate, GDP, VIX)

---

## ğŸ§ª Testing

```bash
# Test database
make test

# Test agents directly
python examples/register_agents.py

# Test LLM agents
python examples/llm_agent_example.py

# Test RAG agents
python examples/rag_agents.py

# Test API
python main.py
curl http://localhost:8000/health
```

---

## ğŸ¯ RAG Options Comparison

| Configuration | Quality | Speed | Setup | Persistent |
|---------------|---------|-------|-------|------------|
| simple + memory | â­ | âš¡âš¡âš¡ | 0 min | âŒ |
| ST + chroma | â­â­â­â­â­ | âš¡âš¡ | 5 min | âœ… |
| ST + faiss | â­â­â­â­â­ | âš¡âš¡âš¡ | 5 min | Manual |
| ollama + chroma | â­â­â­â­ | âš¡ | 10 min | âœ… |

*ST = sentence-transformers*

**Recommended:** sentence-transformers + ChromaDB

---

## ğŸ”§ Troubleshooting

### **Database won't start**
```bash
make clean
make start
```

### **Port 5432 in use**
```bash
# Stop local PostgreSQL
sudo systemctl stop postgresql
# or change port in docker-compose.yml
```

### **Ollama not connecting**
```bash
# Start Ollama
ollama serve

# Pull model
ollama pull llama3.2

# Test
ollama run llama3.2 "Hello"
```

### **Module not found errors**
```bash
# Install in development mode
pip install -e .

# Or add to PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

### **RAG dependencies missing**
```bash
# Check what's installed
pip list | grep -E "sentence|chroma|faiss"

# Install recommended setup
pip install sentence-transformers chromadb
```

See [TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md) for more.

---

## ğŸ“š Documentation

- **API Docs**: http://localhost:8000/docs (when running)
- **ReDoc**: http://localhost:8000/redoc
- **Quick Start**: [QUICK_START.md](docs/QUICK_START.md)
- **RAG Guide**: [RAG_USAGE.md](docs/RAG_USAGE.md)
- **Docker Guide**: [DOCKER_README.md](docs/DOCKER_README.md)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Application                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  POST /analyze  â†’  Background Task  â†’  Consensus  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Agent     â”‚ â”‚    Agent     â”‚ â”‚    Agent     â”‚
â”‚   Registry   â”‚ â”‚   Context    â”‚ â”‚   Signals    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚
       â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Database (PostgreSQL)        â”‚
â”‚    Connection Pool (2-10 conns)   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Mock Data for 5 Stocks    â”‚  â”‚
â”‚  â”‚  - Fundamentals            â”‚  â”‚
â”‚  â”‚  - Prices + Indicators     â”‚  â”‚
â”‚  â”‚  - News + Sentiment        â”‚  â”‚
â”‚  â”‚  - SEC Filings             â”‚  â”‚
â”‚  â”‚  - Options + Macro         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Optional Extensions:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     LLM      â”‚  â”‚     RAG      â”‚  â”‚  Sentiment   â”‚
â”‚  - Ollama    â”‚  â”‚ - Embeddings â”‚  â”‚   - VADER    â”‚
â”‚  - OpenAI    â”‚  â”‚ - VectorDB   â”‚  â”‚   - FinBERT  â”‚
â”‚  - Claude    â”‚  â”‚ - Retrieval  â”‚  â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» Development

### **Running Locally**
```bash
# Start database
make start

# Install dependencies
pip install -e .

# Run API (hot reload)
uvicorn agent_builder.api.app:app --reload

# Or
python main.py
```

### **Running in Docker**
```bash
# Full stack (API + DB)
docker-compose -f docker-compose.full.yml up

# Database only
docker-compose up -d postgres
```

### **Code Quality**
```bash
# Format code
black .

# Lint
flake8 agent_builder/

# Type check
mypy agent_builder/
```

---

## ğŸ§ª Testing

```bash
# Install test dependencies
pip install pytest pytest-asyncio

# Run tests
pytest tests/

# With coverage
pytest --cov=agent_builder tests/
```

---

## ğŸ“ˆ Performance

- **Connection Pooling**: 50x faster than creating new connections
- **Agent Caching**: Caches fundamental data per analysis
- **Background Processing**: Non-blocking analysis execution
- **Optimized Queries**: Indexed tables for fast retrieval

**Benchmarks** (5 agents analyzing AAPL):
- Cold start: ~2 seconds
- Warm (cached): ~500ms
- Database query: ~5ms (with pooling)

---

## ğŸ” Security

- âœ… Input validation (ticker, agent IDs)
- âœ… SQL injection prevention (table whitelist)
- âœ… Parameterized queries
- âœ… CORS configuration
- âœ… Environment-based secrets

---

## ğŸ“¦ Dependencies

### **Core** (Required)
```
fastapi, uvicorn, pydantic, psycopg2-binary, python-dotenv, requests
```

### **RAG** (Optional - Recommended)
```
sentence-transformers, chromadb
```

### **Performance** (Optional)
```
faiss-cpu, numpy
```

See [requirements.txt](requirements.txt) for complete list.

---

## ğŸ› ï¸ Extending the System

### **Add a Custom Agent**
```python
from agent_builder import agent, get_registry

@agent("My Custom Agent", "Description")
def my_agent(ticker, context):
    # Your analysis logic
    data = context.get_fundamental("pe_ratio")
    return "bullish", 0.8, "Your reasoning"

registry = get_registry()
registry.register(my_agent.agent, weight=1.0)
```

### **Add a Custom Data Source**
```python
# In agent_builder/agents/context.py
class AgentContext:
    def get_custom_data(self, ticker):
        return self.db.execute(
            "SELECT * FROM my_custom_table WHERE ticker = %s",
            (ticker,)
        )
```

### **Add a Custom LLM Provider**
```python
# In agent_builder/llm/providers.py
class MyLLMProvider(BaseLLMProvider):
    def generate(self, prompt, **kwargs):
        # Your implementation
        pass
```

---

## ğŸŒ Production Deployment

### **Environment Setup**
1. Set production DATABASE_URL
2. Configure CORS origins
3. Set DEBUG=false
4. Use production-grade secrets management

### **Scaling**
- Increase database connection pool size
- Use Redis for caching (future enhancement)
- Deploy multiple API instances behind load balancer
- Use managed vector database (Pinecone, Weaviate)

### **Monitoring**
- Enable logging to file
- Add metrics endpoint
- Monitor database connection pool
- Track LLM token usage

---

## ğŸ“„ License

MIT License - See [LICENSE](docs/LICENSE) file

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-agent`)
3. Commit changes (`git commit -m 'Add amazing agent'`)
4. Push to branch (`git push origin feature/amazing-agent`)
5. Open Pull Request

---

## ğŸ†˜ Support

- **Issues**: GitHub Issues
- **Discussions**: GitHub Discussions
- **Documentation**: [docs/](docs/)

---

## ğŸ™ Acknowledgments

- FastAPI for the excellent web framework
- Sentence Transformers for semantic embeddings
- ChromaDB for easy vector storage
- Ollama for local LLM inference
- PostgreSQL for reliable data storage

---

## ğŸ“Š Roadmap

- [x] Multi-agent framework
- [x] LLM integration (Ollama, OpenAI, Claude)
- [x] RAG system with multiple backends
- [x] Docker containerization
- [x] Mock database for testing
- [ ] Real-time data integration
- [ ] Backtesting framework
- [ ] Portfolio optimization
- [ ] Web dashboard
- [ ] Agent performance metrics
- [ ] A/B testing for agents

---

**Built with â¤ï¸ for intelligent stock analysis**

---
