# RAG Framework Usage Guide

## ðŸŽ¯ Configuration Options

### Embedding Models (Choose One)

| Provider | Setup | Quality | Speed | Use Case |
|----------|-------|---------|-------|----------|
| **simple** | None | Low | Instant | Testing only |
| **sentence-transformers** | pip install sentence-transformers | High | Fast | Recommended |
| **ollama** | ollama pull nomic-embed-text | Medium | Medium | Fully local |

### Vector Stores (Choose One)

| Store | Setup | Persistence | Speed | Scale |
|-------|-------|-------------|-------|-------|
| **memory** | None | No | Fast | <10K docs |
| **chroma** | pip install chromadb | Yes | Fast | <100K docs |
| **faiss** | pip install faiss-cpu | Manual | Very Fast | <1M docs |

## ðŸš€ Quick Start

### Option 1: Minimal (No Install)
```python
rag = RAGEngine(
    db=db,
    embedding="simple",
    vectorstore="memory"
)
```

### Option 2: Recommended (Best Quality)
```python
# Install: pip install sentence-transformers chromadb

rag = RAGEngine(
    db=db,
    embedding="sentence-transformers",
    embedding_model="all-MiniLM-L6-v2",
    vectorstore="chroma",
    collection_name="my_analysis"
)
```

### Option 3: High Performance
```python
# Install: pip install sentence-transformers faiss-cpu

rag = RAGEngine(
    db=db,
    embedding="sentence-transformers",
    vectorstore="faiss"
)
```

### Option 4: Fully Local (Ollama)
```python
# Install: pip install chromadb
# Pull: ollama pull nomic-embed-text

rag = RAGEngine(
    db=db,
    embedding="ollama",
    embedding_model="nomic-embed-text",
    vectorstore="chroma"
)
```

## ðŸ“ Using in Agents

```python
from agent_builder import agent
from agent_builder.rag import RAGEngine

@agent("My RAG Agent")
def my_rag_agent(ticker, context):
    # Create RAG engine with your choice
    rag = RAGEngine(
        db=context.db,
        embedding="sentence-transformers",  # Choose here
        vectorstore="chroma"                # Choose here
    )
    
    # Index documents
    rag.index_sec_filings(ticker)
    
    # Search
    results = rag.search_sec_filings("growth strategy", ticker=ticker)
    
    # Use results in your analysis
    ...
```

## ðŸ§ª Testing

```bash
# Test all configurations
python examples/rag_agents.py

# Or test in API
python main.py

# Then analyze
curl -X POST http://localhost:8000/analyze \\
  -H "Content-Type: application/json" \\
  -d '{"ticker":"AAPL"}'
```

## ðŸ”„ Switching Between Options

You can switch embedding/vector store combinations anytime:

```python
# Development (no install)
rag_dev = RAGEngine(db, embedding="simple", vectorstore="memory")

# Production (quality)
rag_prod = RAGEngine(db, embedding="sentence-transformers", vectorstore="chroma")

# Performance (speed)
rag_fast = RAGEngine(db, embedding="sentence-transformers", vectorstore="faiss")
```

## ðŸ’¾ Persistence

| Store | Persistent? | Location |
|-------|-------------|----------|
| memory | âŒ No | RAM only |
| chroma | âœ… Yes | ./chroma_db/ |
| faiss | âœ… Manual | Use save()/load() |

## ðŸ“Š Performance Comparison

Tested on 5 SEC filings (~5KB each):

| Configuration | Index Time | Search Time | Quality |
|---------------|------------|-------------|---------|
| simple + memory | <1ms | <1ms | â­ |
| ST + chroma | ~2s | ~50ms | â­â­â­â­â­ |
| ST + faiss | ~2s | ~10ms | â­â­â­â­â­ |
| ollama + chroma | ~10s | ~100ms | â­â­â­â­ |

## ðŸŽ¯ Recommendations

**Start:** simple + memory (test workflow)
**Develop:** sentence-transformers + chroma (best quality)
**Scale:** sentence-transformers + faiss (best performance)
**Privacy:** ollama + chroma (fully local)